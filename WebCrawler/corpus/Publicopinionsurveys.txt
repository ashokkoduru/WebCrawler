<div class="mw-content-ltr" dir="ltr" id="mw-content-text" lang="en"><script>function mfTempOpenSection(id){var block=document.getElementById("mf-section-"+id);block.className+=" open-block";block.previousSibling.className+=" open-block";}</script>
<p>An <b>opinion poll</b>, sometimes simply referred to as a <b>poll</b>, is a <a href="/wiki/Survey_(human_research)" title="Survey (human research)">human research survey</a> of <a href="/wiki/Public_opinion" title="Public opinion">public opinion</a> from a particular <a href="/wiki/Sampling_(statistics)" title="Sampling (statistics)">sample</a>. Opinion polls are usually designed to represent the opinions of a population by conducting a series of questions and then extrapolating generalities in ratio or within <a class="mw-redirect" href="/wiki/Confidence_intervals" title="Confidence intervals">confidence intervals</a>.</p>
<p></p>

<p></p>
<h2><span class="mw-headline" id="History">History</span></h2>
<p>The first known example of an opinion poll was a local <a href="/wiki/Straw_poll" title="Straw poll">straw poll</a> conducted by <i>The Aru Pennsylvanian</i> in <a href="/wiki/United_States_presidential_election,_1824" title="United States presidential election, 1824">1824</a>, showing <a href="/wiki/Andrew_Jackson" title="Andrew Jackson">Andrew Jackson</a> leading <a href="/wiki/John_Quincy_Adams" title="John Quincy Adams">John Quincy Adams</a> by 335 votes to 169 in the contest for the <a class="mw-redirect" href="/wiki/United_States_Presidency" title="United States Presidency">United States Presidency</a>. Since Jackson won the popular vote in that state and the whole country, such straw votes gradually became more popular, but they remained local, usually city-wide phenomena. In 1916, <i><a href="/wiki/The_Literary_Digest" title="The Literary Digest">The Literary Digest</a></i> embarked on a national survey (partly as a circulation-raising exercise) and correctly predicted <a href="/wiki/Woodrow_Wilson" title="Woodrow Wilson">Woodrow Wilson</a>'s election as president. Mailing out millions of <a href="/wiki/Postcard" title="Postcard">postcards</a> and simply counting the returns, <i>The Literary Digest</i> correctly predicted the victories of <a class="mw-redirect" href="/wiki/Warren_Harding" title="Warren Harding">Warren Harding</a> in 1920, <a href="/wiki/Calvin_Coolidge" title="Calvin Coolidge">Calvin Coolidge</a> in 1924, <a href="/wiki/Herbert_Hoover" title="Herbert Hoover">Herbert Hoover</a> in 1928, and <a class="mw-redirect" href="/wiki/Franklin_Roosevelt" title="Franklin Roosevelt">Franklin Roosevelt</a> in 1932.</p>

<p>Then, in <a href="/wiki/United_States_presidential_election,_1936" title="United States presidential election, 1936">1936</a>, its 2.3 million "voters" constituted a huge sample, but they were generally more affluent Americans who tended to have <a class="mw-redirect" href="/wiki/United_States_Republican_Party" title="United States Republican Party">Republican</a> sympathies. <i>The Literary Digest</i> was ignorant of this new bias; the week before election day, it reported that <a href="/wiki/Alf_Landon" title="Alf Landon">Alf Landon</a> was far more popular than Roosevelt. At the same time, <a href="/wiki/George_Gallup" title="George Gallup">George Gallup</a> conducted a far smaller (but more scientifically based) survey, in which he polled a demographically representative sample. Gallup correctly predicted Roosevelt's landslide victory. <i>The Literary Digest</i> soon went out of business, while polling started to take off.</p>
<p><a href="/wiki/Elmo_Roper" title="Elmo Roper">Elmo Roper</a> was another American pioneer in <a href="/wiki/Political_forecasting" title="Political forecasting">political forecasting</a> using scientific polls. He predicted the reelection of President Franklin D. Roosevelt three times, in 1936, 1940, and 1944. <a href="/wiki/Louis_Harris" title="Louis Harris">Louis Harris</a> had been in the field of public opinion since 1947 when he joined the Elmo Roper firm, then later became partner.</p>
<p>In September 1938 Jean Stoetzel, after having met Gallup, created IFOP, the Institut Français d'Opinion Publique, as the first European survey institute in Paris and started political polls in summer 1939 with the question "<a href="/wiki/Why_Die_for_Danzig%3F" title="Why Die for Danzig?">Why die for Danzig?</a>", looking for popular support or dissent with this question asked by appeasement politician and future collaborationist <a href="/wiki/Marcel_D%C3%A9at" title="Marcel Déat">Marcel Déat</a>.</p>
<p><a class="mw-redirect" href="/wiki/The_Gallup_Organization" title="The Gallup Organization">Gallup</a> launched a subsidiary in the <a href="/wiki/United_Kingdom" title="United Kingdom">United Kingdom</a> that, almost alone, correctly predicted <a href="/wiki/Labour_Party_(UK)" title="Labour Party (UK)">Labour's</a> victory in the <a href="/wiki/United_Kingdom_general_election,_1945" title="United Kingdom general election, 1945">1945 general election</a>, unlike virtually all other commentators, who expected a victory for the <a href="/wiki/Conservative_Party_(UK)" title="Conservative Party (UK)">Conservative Party</a>, led by <a href="/wiki/Winston_Churchill" title="Winston Churchill">Winston Churchill</a>.</p>
<p>The Allied occupation powers helped to create survey institutes in all of the Western occupation zones of Germany in 1947 and 1948 to better steer <a href="/wiki/Denazification" title="Denazification">denazification</a>. By the 1950s, various types of polling had spread to most democracies.</p>
<p>In long-term perspective, advertising had come under heavy pressure in the early 1930s. The Great Depression forced businesses to drastically cut back on their advertising spending. Layoffs and reductions were common at all agencies. The <a href="/wiki/New_Deal" title="New Deal">New Deal</a> furthermore aggressively promoted consumerism, and minimized the value of (or need for) advertising. Historian Jackson Lears argues that "By the late 1930s, though, corporate advertisers had begun a successful counterattack against their critics." They rehabilitated the concept of consumer sovereignty by inventing scientific public opinion polls, and making it the centerpiece of their own market research, as well as the key to understanding politics. <a href="/wiki/George_Gallup" title="George Gallup">George Gallup</a>, the vice president of Young and Rubicon, and numerous other advertising experts, led the way. Moving into the 1940s, the industry played a leading role in the ideological mobilization of the American people for fighting the Nazis and Japanese in World War II. As part of that effort, they redefined the "American Way of Life" in terms of a commitment to free enterprise. "Advertisers," Lears concludes, "played a crucial hegemonic role in creating the consumer culture that dominated post-World War II American society."</p>
<h2><span class="mw-headline" id="Sample_and_polling_methods">Sample and polling methods</span></h2>

<p>Opinion polls for many years were maintained through telecommunications or in person-to-person contact. Methods and techniques vary, though they are widely accepted in most areas. Over the years, technological innovations have also influenced survey methods such as the availability of <a href="/wiki/Ferranti_MRT" title="Ferranti MRT">electronic clipboards</a> and Internet based polling. Verbal, ballot, and processed types can be conducted efficiently, contrasted with other types of surveys, systematics, and complicated matrices beyond previous orthodox procedures.</p>
<p>Opinion polling developed into popular applications through popular thought, although response rates for some surveys declined. Also, the following has also led to differentiating results: Some polling organizations, such as <a href="/wiki/Angus_Reid_Public_Opinion" title="Angus Reid Public Opinion">Angus Reid Public Opinion</a>, <a href="/wiki/YouGov" title="YouGov">YouGov</a> and <a class="mw-redirect" href="/wiki/Zogby_International" title="Zogby International">Zogby</a> use <a href="/wiki/Internet" title="Internet">Internet</a> surveys, where a sample is drawn from a large panel of volunteers, and the results are weighted to reflect the demographics of the population of interest. In contrast, popular web polls draw on whoever wishes to participate, rather than a scientific sample of the population, and are therefore not generally considered professional.</p>
<p>Recently, statistical learning methods have been proposed in order to exploit <a href="/wiki/Social_media" title="Social media">social media</a> content (such as posts on the micro-blogging platform of <a href="/wiki/Twitter" title="Twitter">Twitter</a>) for modelling and predicting voting intention polls.</p>
<p>Polls can be used in the public relations field as well. In the early 1920s, public relation experts described their work as a two-way street. Their job would be to present the misinterpreted interests of large institutions to public. They would also gauge the typically ignored interests of the public through polls.</p>
<h3><span class="mw-headline" id="Benchmark_polls">Benchmark polls</span></h3>
<p>A <i>benchmark poll</i> is generally the first poll taken in a campaign. It is often taken before a candidate announces their bid for office but sometimes it happens immediately following that announcement after they have had some opportunity to raise funds. This is generally a short and simple survey of likely voters.</p>
<p>A <i>benchmark poll</i> serves a number of purposes for a campaign, whether it is a political campaign or some other type of campaign. First, it gives the candidate a picture of where they stand with the electorate before any campaigning takes place. If the poll is done prior to announcing for office the candidate may use the poll to decide whether or not they should even run for office. Secondly, it shows them where their weaknesses and strengths are in two main areas. The first is the electorate. A <i>benchmark poll</i> shows them what types of voters they are sure to win, those who they are sure to lose, and everyone in-between those two extremes. This lets the campaign know which voters are persuadable so they can spend their limited resources in the most effective manner. Second, it can give them an idea of what messages, ideas, or slogans are the strongest with the electorate.</p>
<h3><span class="mw-headline" id="Brushfire_polls">Brushfire polls</span></h3>
<p><i>Brushfire polls</i> are polls taken during the period between the <i>benchmark poll</i> and <i>tracking polls</i>. The number of <i>brushfire polls</i> taken by a campaign is determined by how competitive the race is and how much money the campaign has to spend. These polls usually focus on likely voters and the length of the survey varies on the number of messages being tested.</p>
<p><i>Brushfire polls</i> are used for a number of purposes. First, it lets the candidate know if they have made any progress on the ballot, how much progress has been made, and in what demographics they have been making or losing ground. Secondly, it is a way for the campaign to test a variety of messages, both positive and negative, on themselves and their opponent(s). This lets the campaign know what messages work best with certain demographics and what messages should be avoided. Campaigns often use these polls to test possible attack messages that their opponent may use and potential responses to those attacks. The campaign can then spend some time preparing an effective response to any likely attacks. Thirdly, this kind of poll can be used by candidates or political parties to convince primary challengers to drop out of a race and support a stronger candidate.</p>
<h3><span class="mw-headline" id="Tracking_polls">Tracking polls</span></h3>
<p>A <i>tracking poll</i> is a poll repeated at intervals generally averaged over a <a class="new" href="/w/index.php?title=Trailing_window&amp;action=edit&amp;redlink=1" title="Trailing window (page does not exist)">trailing window</a>. For example, a weekly tracking poll uses the data from the past week and discards older data.</p>
<p>A caution is that estimating the trend is more difficult and error-prone than estimating the level – intuitively, if one estimates the change, the difference between two numbers <i>X</i> and <i>Y,</i> then one has to contend with the error in both <i>X</i> and <i>Y</i> – it is not enough to simply take the difference, as the change may be random noise. For details, see <a class="mw-redirect" href="/wiki/T-test" title="T-test">t-test</a>. A rough guide is that if the change in measurement falls outside the margin of error, it is worth attention.</p>
<h2><span class="mw-headline" id="Potential_for_inaccuracy">Potential for inaccuracy</span></h2>

<p>Polls based on samples of populations are subject to <a href="/wiki/Sampling_error" title="Sampling error">sampling error</a> which reflects the effects of chance and uncertainty in the sampling process. The uncertainty is often expressed as a <a href="/wiki/Margin_of_error" title="Margin of error">margin of error</a>. The margin of error is usually defined as the radius of a confidence interval for a particular statistic from a survey. One example is the percent of people who prefer product A versus product B. When a single, global margin of error is reported for a survey, it refers to the maximum margin of error for all reported percentages using the full sample from the survey. If the statistic is a percentage, this maximum margin of error can be calculated as the radius of the confidence interval for a reported percentage of 50%. Others suggest that a poll with a random sample of 1,000 people has margin of sampling error of 3% for the estimated percentage of the whole population.</p>
<p>A 3% margin of error means that if the same procedure is used a large number of times, 95% of the time the true population average will be within the 95% confidence interval of the sample estimate plus or minus 3%. The margin of error can be reduced by using a larger sample, however if a pollster wishes to reduce the margin of error to 1% they would need a sample of around 10,000 people. In practice, pollsters need to balance the cost of a large sample against the reduction in sampling error and a sample size of around 500–1,000 is a typical compromise for political polls. (Note that to get complete responses it may be necessary to include thousands of additional participators.)</p>
<p>Another way to reduce the margin of error is to rely on <a href="/wiki/Poll_average" title="Poll average">poll averages</a>. This makes the assumption that the procedure is similar enough between many different polls and uses the sample size of each poll to create a polling average. An example of a polling average can be found here: <a class="external text" href="http://www.daytodaypolitics.com/polls/presidential_election_Obama_vs_McCain_2008.htm" rel="nofollow">2008 Presidential Election polling average</a>. Another source of error stems from faulty demographic models by pollsters who weigh their samples by particular variables such as party identification in an election. For example, if you assume that the breakdown of the US population by party identification has not changed since the previous presidential election, you may underestimate a victory or a defeat of a particular party candidate that saw a surge or decline in its party registration relative to the previous presidential election cycle.</p>
<p>Over time, a number of theories and mechanisms have been offered to explain erroneous polling results. Some of these reflect errors on the part of the pollsters; many of them are statistical in nature. Others blame the respondents for not giving candid answers (<i>e.g.</i>, the <a href="/wiki/Bradley_effect" title="Bradley effect">Bradley effect</a>, the <a href="/wiki/Shy_Tory_Factor" title="Shy Tory Factor">Shy Tory Factor</a>); these can be more controversial.</p>
<h3><span class="mw-headline" id="Nonresponse_bias">Nonresponse bias</span></h3>
<p>Since some people do not answer calls from strangers, or refuse to answer the poll, poll samples may not be representative samples from a population due to a <a href="/wiki/Non-response_bias" title="Non-response bias">non-response bias</a>. Response rates have been declining, and are down to about 10% in recent years. Because of this <a href="/wiki/Selection_bias" title="Selection bias">selection bias</a>, the characteristics of those who agree to be interviewed may be markedly different from those who decline. That is, the actual sample is a biased version of the universe the pollster wants to analyze. In these cases, bias introduces new errors, one way or the other, that are in addition to errors caused by sample size. Error due to bias does not become smaller with larger sample sizes, because taking a larger sample size simply repeats the same mistake on a larger scale. If the people who refuse to answer, or are never reached, have the same characteristics as the people who do answer, then the final results should be unbiased. If the people who do not answer have different opinions then there is bias in the results. In terms of election polls, studies suggest that bias effects are small, but each polling firm has its own techniques for adjusting weights to minimize selection bias.</p>
<h3><span class="mw-headline" id="Response_bias">Response bias</span></h3>
<p>Survey results may be affected by <a href="/wiki/Response_bias" title="Response bias">response bias</a>, where the answers given by respondents do not reflect their true beliefs. This may be deliberately engineered by unscrupulous pollsters in order to generate a certain result or please their clients, but more often is a result of the detailed wording or ordering of questions (see below). Respondents may deliberately try to manipulate the outcome of a poll by e.g. advocating a more extreme position than they actually hold in order to boost their side of the argument or give rapid and ill-considered answers in order to hasten the end of their questioning. Respondents may also feel under social pressure not to give an unpopular answer. For example, respondents might be unwilling to admit to unpopular attitudes like <a href="/wiki/Racism" title="Racism">racism</a> or <a href="/wiki/Sexism" title="Sexism">sexism</a>, and thus polls might not reflect the true incidence of these attitudes in the population. In American political parlance, this phenomenon is often referred to as the <a href="/wiki/Bradley_effect" title="Bradley effect">Bradley effect</a>. If the results of surveys are widely publicized this effect may be magnified - a phenomenon commonly referred to as the <a href="/wiki/Spiral_of_silence" title="Spiral of silence">spiral of silence</a>.</p>
<p>Use of the <a href="/wiki/Plurality_voting_system" title="Plurality voting system">plurality voting system</a> (select only one candidate) in a poll puts an unintentional bias into the poll, since people who favor more than one candidate cannot indicate this. The fact that they must choose only one candidate biases the poll, causing it to favor the candidate most different from the others while it disfavors candidates who are similar to other candidates. The <a href="/wiki/Plurality_voting_system" title="Plurality voting system">plurality voting system</a> also biases elections in the same way.</p>
<h3><span class="mw-headline" id="Wording_of_questions">Wording of questions</span></h3>
<p>It is well established that the wording of the questions, the order in which they are asked and the number and form of alternative answers offered can influence results of polls. For instance, the public is more likely to indicate support for a person who is described by the operator as one of the "leading candidates". This support itself overrides subtle bias for one candidate, as does lumping some candidates in an "other" category or vice versa. Thus comparisons between polls often boil down to the wording of the question. On some issues, question wording can result in quite pronounced differences between surveys. This can also, however, be a result of legitimately conflicted feelings or evolving attitudes, rather than a poorly constructed survey.</p>
<p>A common technique to control for this bias is to rotate the order in which questions are asked. Many pollsters also split-sample. This involves having two different versions of a question, with each version presented to half the respondents.</p>
<p>The most effective controls, used by <a href="/wiki/Attitude_(psychology)" title="Attitude (psychology)">attitude</a> researchers, are:</p>
<ul>
<li>asking enough questions to allow all aspects of an issue to be covered and to control effects due to the form of the question (such as positive or negative wording), the adequacy of the number being established quantitatively with <a href="/wiki/Psychometrics" title="Psychometrics">psychometric</a> measures such as reliability coefficients, and</li>
<li>analyzing the results with psychometric techniques which synthesize the answers into a few reliable scores and detect ineffective questions.</li>
</ul>
<p>These controls are not widely used in the polling industry.</p>
<h3><span class="mw-headline" id="Coverage_bias">Coverage bias</span></h3>
<p>Another source of error is the use of samples that are not representative of the population as a consequence of the methodology used, as was the experience of <i>The Literary Digest</i> in 1936. For example, telephone sampling has a built-in error because in many times and places, those with telephones have generally been richer than those without.</p>
<p>In some places many people have only <a class="mw-redirect" href="/wiki/Mobile_telephone" title="Mobile telephone">mobile telephones</a>. Because pollsters cannot use automated dialing machines to call mobile phones in the United States (because the phone's owner may be charged for taking a call), these individuals are typically excluded from polling samples. There is concern that, if the subset of the population without cell phones differs markedly from the rest of the population, these differences can skew the results of the poll.</p>
<p>Polling organizations have developed many weighting techniques to help overcome these deficiencies, with varying degrees of success. Studies of mobile phone users by the Pew Research Center in the US, in 2007, concluded that "cell-only respondents are different from landline respondents in important ways, (but) they were neither numerous enough nor different enough on the questions we examined to produce a significant change in overall general population survey estimates when included with the landline samples and weighted according to US Census parameters on basic demographic characteristics."</p>
<p>This issue was first identified in 2004, but came to prominence only during the 2008 <a href="/wiki/United_States_presidential_election,_2008" title="United States presidential election, 2008">US presidential election</a>. In previous elections, the proportion of the general population using cell phones was small, but as this proportion has increased, there is concern that polling only landlines is no longer representative of the general population. In 2003, only 2.9% of households were wireless (cellphones only), compared to 12.8% in 2006. This results in "<a href="/wiki/Coverage_error" title="Coverage error">coverage error</a>". Many polling organisations select their sample by dialling random telephone numbers; however, in 2008, there was a clear tendency for polls which included mobile phones in their samples to show a much larger lead for <a href="/wiki/Barack_Obama" title="Barack Obama">Obama</a>, than polls that did not.</p>
<p>The potential sources of bias are:</p>
<ol>
<li>Some households use cellphones only and have no landline. This tends to include minorities and younger voters; and occurs more frequently in metropolitan areas. Men are more likely to be cellphone-only compared to women.</li>
<li>Some people may not be contactable by landline from Monday to Friday and may be contactable only by cellphone.</li>
<li>Some people use their landlines only to access the Internet, and answer calls only to their cellphones.</li>
</ol>
<p>Some polling companies have attempted to get around that problem by including a "cellphone supplement". There are a number of problems with including cellphones in a telephone poll:</p>
<ol>
<li>It is difficult to get co-operation from cellphone users, because in many parts of the US, users are charged for both outgoing and incoming calls. That means that pollsters have had to offer financial compensation to gain co-operation.</li>
<li>US federal law prohibits the use of automated dialling devices to call cellphones (<a href="/wiki/Telephone_Consumer_Protection_Act_of_1991" title="Telephone Consumer Protection Act of 1991">Telephone Consumer Protection Act of 1991</a>). Numbers therefore have to be dialled by hand, which is more time-consuming and expensive for pollsters.</li>
</ol>
<p>An oft-quoted example of opinion polls succumbing to errors occurred during the <a href="/wiki/United_Kingdom_general_election,_1992" title="United Kingdom general election, 1992">1992 UK general election</a>. Despite the polling organizations using different methodologies, virtually all the polls taken before the vote, and to a lesser extent, <a href="/wiki/Exit_poll" title="Exit poll">exit polls</a> taken on voting day, showed a lead for the opposition Labour party, but the actual vote gave a clear victory to the ruling Conservative party.</p>
<p>In their deliberations after this embarrassment the pollsters advanced several ideas to account for their errors, including:</p>

<p>The relative importance of these factors was, and remains, a matter of controversy, but since then the polling organizations have adjusted their methodologies and have achieved more accurate results in subsequent election campaigns.</p>
<p>A comprehensive discussion of these biases and how they should be understood and mitigated is included in several sources including Dillman and Salant (1994).</p>
<h2><span class="mw-headline" id="Failures">Failures</span></h2>
<p>A widely publicized failure of opinion polling to date in the <a href="/wiki/United_States" title="United States">United States</a> was the prediction that <a class="mw-redirect" href="/wiki/Thomas_Dewey" title="Thomas Dewey">Thomas Dewey</a> would defeat <a href="/wiki/Harry_S._Truman" title="Harry S. Truman">Harry S. Truman</a> in the <a class="mw-redirect" href="/wiki/U.S._presidential_election,_1948" title="U.S. presidential election, 1948">1948 US presidential election</a>. Major polling organizations, including Gallup and Roper, indicated a landslide victory for Dewey.</p>
<p>In the United Kingdom, most polls failed to predict the Conservative election victories of <a href="/wiki/United_Kingdom_general_election,_1970" title="United Kingdom general election, 1970">1970</a> and <a href="/wiki/United_Kingdom_general_election,_1992" title="United Kingdom general election, 1992">1992</a>, and Labour's victory in <a href="/wiki/United_Kingdom_general_election,_February_1974" title="United Kingdom general election, February 1974">1974</a>. However, their figures at other elections have been generally accurate. In the <a href="/wiki/United_Kingdom_general_election,_2015" title="United Kingdom general election, 2015">2015 election</a> virtually every poll predicted a hung parliament with Labour and the Conservatives neck and neck when the actual result was a clear Conservative majority.</p>
<h2><span class="mw-headline" id="Social_media_as_a_source_of_opinion_on_candidates">Social media as a source of opinion on candidates</span></h2>
<p>Social media today is a popular medium for the candidates to campaign and for gauging the public reaction to the campaigns. Social media can also be used as an indicator of the voter opinion regarding the poll. Some research studies have shown that predictions made using social media signals can match traditional opinion polls.</p>
<h2><span class="mw-headline" id="Influence">Influence</span></h2>
<h3><span class="mw-headline" id="Effect_on_voters">Effect on voters</span></h3>
<p>By providing information about voting intentions, opinion polls can sometimes influence the behavior of electors, and in his book <i><a class="mw-redirect" href="/wiki/The_Broken_Compass:_How_British_Politics_Lost_its_Way" title="The Broken Compass: How British Politics Lost its Way">The Broken Compass</a></i>, <a href="/wiki/Peter_Hitchens" title="Peter Hitchens">Peter Hitchens</a> asserts that opinion polls are actually a device for influencing public opinion. The various theories about how this happens can be split into two groups: bandwagon/underdog effects, and strategic ("tactical") voting.</p>
<p>A <a href="/wiki/Bandwagon_effect" title="Bandwagon effect">bandwagon effect</a> occurs when the poll prompts voters to back the candidate shown to be winning in the poll. The idea that voters are susceptible to such effects is old, stemming at least from 1884; <a href="/wiki/William_Safire" title="William Safire">William Safire</a> reported that the term was first used in a political cartoon in the magazine <i><a href="/wiki/Puck_(magazine)" title="Puck (magazine)">Puck</a></i> in that year. It has also remained persistent in spite of a lack of empirical corroboration until the late 20th century. <a href="/wiki/George_Gallup" title="George Gallup">George Gallup</a> spent much effort in vain trying to discredit this theory in his time by presenting empirical research. A recent meta-study of scientific research on this topic indicates that from the 1980s onward the Bandwagon effect is found more often by researchers.</p>
<p>The opposite of the bandwagon effect is the <a class="mw-redirect" href="/wiki/Underdog_(competition)" title="Underdog (competition)">underdog</a> effect. It is often mentioned in the media. This occurs when people vote, out of sympathy, for the party perceived to be "losing" the elections. There is less empirical evidence for the existence of this effect than there is for the existence of the bandwagon effect.</p>
<p>The second category of theories on how polls directly affect voting is called strategic or <a href="/wiki/Tactical_voting" title="Tactical voting">tactical voting</a>. This theory is based on the idea that voters view the act of voting as a means of selecting a government. Thus they will sometimes not choose the candidate they prefer on ground of ideology or sympathy, but another, less-preferred, candidate from strategic considerations. An example can be found in the <a href="/wiki/United_Kingdom_general_election,_1997" title="United Kingdom general election, 1997">United Kingdom general election, 1997</a>. As he was then a Cabinet Minister, <a href="/wiki/Michael_Portillo" title="Michael Portillo">Michael Portillo</a>'s constituency of <a href="/wiki/Enfield_Southgate_(UK_Parliament_constituency)" title="Enfield Southgate (UK Parliament constituency)">Enfield Southgate</a> was believed to be a <a href="/wiki/Safe_seat" title="Safe seat">safe seat</a> but opinion polls showed the <a href="/wiki/Labour_Party_(UK)" title="Labour Party (UK)">Labour</a> candidate <a href="/wiki/Stephen_Twigg" title="Stephen Twigg">Stephen Twigg</a> steadily gaining support, which may have prompted undecided voters or supporters of other parties to support Twigg in order to remove Portillo. Another example is the boomerang effect where the likely supporters of the candidate shown to be winning feel that chances are slim and that their vote is not required, thus allowing another candidate to win.</p>
<p>In addition, Mark Pickup in Cameron Anderson and Laura Stephenson's "Voting Behaviour in Canada" outlines three additional "behavioural" responses that voters may exhibit when faced with polling data.</p>
<p>The first is known as a "cue taking" effect which holds that poll data is used as a "proxy" for information about the candidates or parties. Cue taking is "based on the psychological phenomenon of using heuristics to simplify a complex decision" (243).</p>
<p>The second, first described by Petty and Cacioppo (1996) is known as "cognitive response" theory. This theory asserts that a voter's response to a poll may not line with their initial conception of the electoral reality. In response, the voter is likely to generate a "mental list" in which they create reasons for a party's loss or gain in the polls. This can reinforce or change their opinion of the candidate and thus affect voting behaviour.</p>
<p>Third, the final possibility is a "behavioural response" which is similar to a cognitive response. The only salient difference is that a voter will go and seek new information to form their "mental list", thus becoming more informed of the election. This may then affect voting behaviour.</p>
<p>These effects indicate how opinion polls can directly affect political choices of the electorate. But directly or indirectly, other effects can be surveyed and analyzed on all political parties. The form of <a href="/wiki/Framing_(social_sciences)" title="Framing (social sciences)">media framing</a> and party ideology shifts must also be taken under consideration. Opinion polling in some instances is a measure of cognitive bias, which is variably considered and handled appropriately in its various applications.</p>
<h3><span class="mw-headline" id="Effect_on_politicians">Effect on politicians</span></h3>


<p>Starting in the 1980s, tracking polls and related technologies began having a notable impact on U.S. political leaders. According to Douglas Bailey, a Republican who had helped run <a href="/wiki/Gerald_Ford" title="Gerald Ford">Gerald Ford</a>'s <a href="/wiki/United_States_presidential_election,_1976" title="United States presidential election, 1976">1976 presidential campaign</a>, "It's no longer necessary for a political candidate to guess what an audience thinks. He can [find out] with a nightly tracking poll. So it's no longer likely that political leaders are going to lead. Instead, they're going to follow."</p>
<h2><span class="mw-headline" id="Regulation">Regulation</span></h2>
<p>Some jurisdictions over the world restrict the publication of the results of opinion polls, especially during the period around an election, in order to prevent the possibly erroneous results from affecting voters' decisions. For instance, in Canada, it is prohibited to publish the results of opinion surveys that would identify specific political parties or candidates in the final three days before a poll closes.</p>
<p>However, most <a class="mw-redirect" href="/wiki/Western_democratic_nations" title="Western democratic nations">western democratic nations</a> don't support the entire prohibition of the publication of pre-election opinion polls; most of them have no regulation and some only prohibit it in the final days or hours until the relevant poll closes. A survey by Canada's Royal Commission on Electoral Reform reported that the prohibition period of publication of the survey results largely differed in different countries. Out of the 20 countries examined, 3 prohibit the publication during the entire period of campaigns, while others prohibit it for a shorter term such as the polling period or the final 48 hours before a poll closes. In India, the Election Commission has prohibited it in the 48 hours before the start of polling.</p>
<h2><span class="mw-headline" id="See_also">See also</span></h2>
<ul>
<li><a href="/wiki/Deliberative_opinion_poll" title="Deliberative opinion poll">Deliberative opinion poll</a></li>
<li><a href="/wiki/Entrance_poll" title="Entrance poll">Entrance poll</a></li>
<li><a href="/wiki/Everett_Carll_Ladd" title="Everett Carll Ladd">Everett Carll Ladd</a></li>
<li><a href="/wiki/Exit_poll" title="Exit poll">Exit poll</a></li>
<li><a href="/wiki/Historical_polling_for_U.S._Presidential_elections" title="Historical polling for U.S. Presidential elections">Historical polling for U.S. Presidential elections</a></li>
<li><a href="/wiki/List_of_polling_organizations" title="List of polling organizations">List of polling organizations</a></li>
<li><a href="/wiki/Open_access_poll" title="Open access poll">Open access poll</a></li>
<li><a href="/wiki/Push_poll" title="Push poll">Push poll</a></li>
<li><a href="/wiki/Referendum" title="Referendum">Referendum</a></li>
<li><a href="/wiki/Roper_Center_for_Public_Opinion_Research" title="Roper Center for Public Opinion Research">Roper Center for Public Opinion Research</a></li>
<li><a href="/wiki/Sample_size_determination" title="Sample size determination">Sample size determination</a></li>
<li><a href="/wiki/Straw_poll" title="Straw poll">Straw poll</a></li>
</ul>
<h2><span class="mw-headline" id="Footnotes">Footnotes</span></h2>

<h2></h2>
<ul>
<li>Asher, Herbert: <i>Polling and the Public. What Every Citizen Should Know</i> (4th ed. CQ Press, 1998)</li>
<li><a href="/wiki/Pierre_Bourdieu" title="Pierre Bourdieu">Bourdieu, Pierre</a>, "Public Opinion does not exist" in <i>Sociology in Question</i>, London, Sage (1995).</li>
<li>Bradburn, Norman M. and Seymour Sudman. <i>Polls and Surveys: Understanding What They Tell Us</i> (1988).</li>
<li>Cantril, Hadley. <i>Gauging Public Opinion</i> (1944).</li>
<li><a class="external text" href="http://www.questia.com/PM.qst?a=o&amp;d=98754501" rel="nofollow">Cantril, Hadley and Mildred Strunk, eds. <i>Public Opinion, 1935-1946</i> (1951)</a>, massive compilation of many public opinion polls from US, UK, Canada, Australia, and elsewhere.</li>
<li>Converse, Jean M. <i>Survey Research in the United States: Roots and Emergence 1890-1960</i> (1987), the standard history.</li>
<li><a class="external text" href="http://www.questia.com/PM.qst?a=o&amp;d=8971691" rel="nofollow">Crespi, Irving. <i>Public Opinion, Polls, and Democracy</i> (1989)</a>.</li>
<li>Gallup, George. <i>Public Opinion in a Democracy</i> (1939).</li>
<li>Gallup, Alec M. ed. <i>The Gallup Poll Cumulative Index: Public Opinion, 1935-1997</i> (1999) lists 10,000+ questions, but no results.</li>
<li>Gallup, George Horace, ed. <i>The Gallup Poll; Public Opinion, 1935-1971</i> 3 vol (1972) summarizes results of each poll.</li>
<li>Geer, John Gray. <i>Public opinion and polling around the world: a historical encyclopedia</i> (2 vol. Abc-clio, 2004)</li>
<li><a class="external text" href="http://www.questia.com/PM.qst?a=o&amp;d=100501261" rel="nofollow">Glynn, Carroll J., Susan Herbst, Garrett J. O'Keefe, and Robert Y. Shapiro. <i>Public Opinion</i> (1999)</a> textbook</li>
<li><a class="external text" href="http://www.questia.com/PM.qst?a=o&amp;d=28537852" rel="nofollow">Lavrakas, Paul J. et al. eds. <i>Presidential Polls and the News Media</i> (1995)</a></li>
<li><a class="external text" href="http://www.questia.com/PM.qst?a=o&amp;d=8540600" rel="nofollow">Moore, David W. <i>The Superpollsters: How They Measure and Manipulate Public Opinion in America</i> (1995)</a>.</li>
<li><a class="external text" href="http://www.questia.com/PM.qst?a=o&amp;d=28621255" rel="nofollow">Niemi, Richard G., John Mueller, Tom W. Smith, eds. <i>Trends in Public Opinion: A Compendium of Survey Data</i> (1989)</a>.</li>
<li><a class="external text" href="http://www.questia.com/PM.qst?a=o&amp;d=104829752" rel="nofollow">Oskamp, Stuart and P. Wesley Schultz; <i>Attitudes and Opinions</i> (2004)</a>.</li>
<li>Robinson, Claude E. <i>Straw Votes</i> (1932).</li>
<li>Robinson, Matthew <i>Mobocracy: How the Media's Obsession with Polling Twists the News, Alters Elections, and Undermines Democracy</i> (2002).</li>
<li><a class="external text" href="http://www.questia.com/PM.qst?a=o&amp;d=89021667" rel="nofollow">Rogers, Lindsay. <i>The Pollsters: Public Opinion, Politics, and Democratic Leadership</i> (1949)</a>.</li>
<li><a class="external text" href="http://www.questia.com/PM.qst?a=o&amp;d=71288534" rel="nofollow">Traugott, Michael W. <i>The Voter's Guide to Election Polls</i></a> 3rd ed. (2004).</li>
<li>James G. Webster, Patricia F. Phalen, Lawrence W. Lichty; <i>Ratings Analysis: The Theory and Practice of Audience Research</i> Lawrence Erlbaum Associates, 2000.</li>
<li><a class="external text" href="http://www.questia.com/PM.qst?a=o&amp;d=59669912" rel="nofollow">Young, Michael L. <i>Dictionary of Polling: The Language of Contemporary Opinion Research</i> (1992)</a>.</li>
</ul>
<h3><span class="mw-headline" id="Additional_Sources">Additional Sources</span></h3>
<ul>
<li>Dyczok, Marta. "Information wars: hegemony, counter-hegemony, propaganda, the use of force, and resistance." <i>Russian Journal of Communication</i> 6#2 (2014): 173-176.</li>
<li>Kang, Liu, and Yun-Han Chu. "China's Rise through World Public Opinion: Editorial Introduction." <i>Journal of Contemporary China</i> 24.92 (2015): 197-202; polls in US and China</li>
<li>Kim, So Young, and Yael Wolinsky-Nahmias. "Cross-national public opinion on climate change: the effects of affluence and vulnerability." <i>Global Environmental Politics</i> 14.1 (2014): 79-106.</li>
<li>Murphy, Joe, et al. "Social Media in Public Opinion Research: Report of the AAPOR Task Force on Emerging Technologies in Public Opinion Research." <i>American Association for Public Opinion Research</i> (2014). <a class="external text" href="https://www.aapor.org/AAPORKentico/AAPOR_Main/media/MainSiteFiles/AAPOR_Social_Media_Report_FNL.pdf" rel="nofollow">online</a></li>
<li>Walden, Graham R. <i>Public Opinion Polls and Survey Research: A Selective Annotated Bibliography of US Guides &amp; Studies from the 1980s.</i> (Routledge, 2014)</li>
<li>Walden, Graham R. <i>Survey Research Methodology, 1990-1999: An Annotated Bibliography</i>. (Greenwood, 2002). xx, 432p.</li>
<li>Walden, Graham R. <i>Public Opinion Polls and Survey Research: A Selective Annotated Bibliography of U.S. Guides and Studies from the 1980s</i>. Public Affairs and Administrative Series, edited by James S. Bowman, vol. 24. New York, NY: Garland Publishing Inc., 1990. xxix, 360p.</li>
<li>Walden, Graham R. <i>Polling and Survey Research Methods 1935-1979: An Annotated Bibliography.</i> Bibliographies and Indexes in Law and Political Science Series, vol. 25. Westport, CT: Greenwood Publishing Group, Inc., 1996. xxx, 581p.</li>
</ul>
<h2><span class="mw-headline" id="External_links">External links</span></h2>

<ul>
<li><a class="external text" href="http://ucblibraries.colorado.edu/govpubs/us/polls.htm" rel="nofollow">Polls</a> from <i>UCB Libraries GovPubs</i></li>
<li><a class="external text" href="http://www.pewresearch.org" rel="nofollow">The Pew Research Center</a> nonpartisan "fact tank" providing information on the issues, attitudes and trends shaping America and the world by conducting public opinion polling and social science research</li>
<li><a class="external text" href="http://www.gcastrategies.com/books_articles/article_001_or.php" rel="nofollow">"Use Opinion Research To Build Strong Communication"</a> by Frank Noto</li>
<li><a class="external text" href="http://www.ncpp.org/?q=home" rel="nofollow">National Council on Public Polls</a> association of polling organizations in the United States devoted to setting high professional standards for surveys</li>
<li><a class="external text" href="http://www.i-marvin.si" rel="nofollow">Survey Analysis Tool</a> based on <a class="external text" href="http://dx.doi.org/10.1016/j.jda.2006.01.001" rel="nofollow">A. Berkopec, <i>HyperQuick algorithm for discrete hypergeometric distribution</i>, Journal of Discrete Algorithms, Elsevier, 2006</a>.</li>
</ul>



<!-- Saved in parser cache with key enwiki:pcache:idhash:277315-0!*!0!!en!4!* and timestamp 20161102181145 and revision id 746219301
 -->
<noscript><img alt="" height="1" src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" style="border: none; position: absolute;" title="" width="1"/></noscript></div>